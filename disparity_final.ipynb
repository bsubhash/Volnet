{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = np.array([256,448])\n",
    "batch_size = 32\n",
    "num_batches = 2\n",
    "disparity_levels = 16\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset graph and set up regularizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "(imh,imw) = image_shape\n",
    "#Define Inputs for the network\n",
    "lx = tf.placeholder(tf.float32, (batch_size, imh, imw, 3), name= \"left_image\")\n",
    "ly = tf.placeholder(tf.float32, (batch_size, imh, imw, 3),name= \"right_image\")\n",
    "y = tf.placeholder(tf.float32, (batch_size,imh, imw),name= \"disparity_image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized function for Relu based convolution followed by unary Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu_layer_in(input_layer,inshape,outshape, filter_shape, stride, id):\n",
    "    conv2d_W = tf.get_variable('conv'+str(id), regularizer = regularizer, initializer = tf.truncated_normal(shape=(3, 3, inshape, outshape), mean = mu, stddev = sigma))\n",
    "    conv2d_b = tf.Variable(tf.zeros(outshape),name = 'bias'+str(id))\n",
    "    s   = tf.nn.conv2d(input_layer, conv2d_W, strides=[1,stride, stride,1], padding='SAME') + conv2d_b\n",
    "    s_a = tf.nn.relu(s)\n",
    "    return s_a\n",
    "#generalized function for getting unary features\n",
    "def unary_res(indata, inchannels, outchannels, stride, id):\n",
    "    conv2d_W = tf.get_variable('conv'+str(id), regularizer = regularizer, \n",
    "                               initializer = tf.truncated_normal(shape=(3, 3, inchannels, outchannels),\n",
    "                                                                 mean = mu, stddev = sigma));\n",
    "    conv2d_b = tf.Variable(tf.zeros(outchannels),name = 'bias'+str(id))\n",
    "    s   = tf.nn.conv2d(indata, conv2d_W, strides=[1,stride, stride,1], padding='SAME') + conv2d_b\n",
    "    s_a = tf.nn.relu(s)\n",
    "    return s_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Unary Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.1\n",
    "def get_unary_features(input_tensor_batch):\n",
    "    conv0 = conv_bn_relu_layer_in(input_tensor_batch,3,disparity_levels, [3, 3, 3, disparity_levels], 1, 100)\n",
    "    n = 2;\n",
    "    res_inp = conv0\n",
    "    for i in range(n):\n",
    "        conv1 = unary_res(res_inp, disparity_levels, disparity_levels, 1, i)\n",
    "        tf.Print(conv1, [tf.shape(conv1)], message=\"This is conv1: \",summarize = 5)\n",
    "        conv3 = unary_res(conv1, disparity_levels, disparity_levels, 1, 10+i) #+ res_inp\n",
    "        res_inp = conv3\n",
    "    #final stage of the Unary network        \n",
    "    convu_W = tf.get_variable(\"unary_conv\", initializer = tf.truncated_normal(shape=[3, 3, disparity_levels,disparity_levels], mean = mu, stddev = sigma), regularizer=regularizer)\n",
    "    convu_b = tf.Variable(tf.zeros(disparity_levels))\n",
    "    conv1   = tf.nn.conv2d(res_inp, convu_W, strides=[1, 1, 1, 1 ], padding='SAME') + convu_b\n",
    "\n",
    "    return conv1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cost_volume(lx,ly):\n",
    "    with tf.variable_scope('unary') as unary_scope:\n",
    "        ufx = get_unary_features(lx)\n",
    "        unary_scope.reuse_variables()\n",
    "        ufy = get_unary_features(ly)\n",
    "    u_shape = tf.shape(ufx)\n",
    "    cvu = tf.concat([ufx,ufy], axis = 3)\n",
    "    cvu_shape = tf.shape(cvu)\n",
    "    return cvu\n",
    "#disparity Estimate routine\n",
    "\n",
    "def disparity_estimates_low(lx,ly):\n",
    "    cvd = get_cost_volume(lx,ly)\n",
    "    #get cost volume\n",
    "    s = cvd\n",
    "    #generate another volume of disparity levels*2\n",
    "    for id in range(1):\n",
    "        conv2d_W = tf.get_variable('oebyone'+str(id), initializer = tf.truncated_normal(shape=(1, 1, disparity_levels*2, disparity_levels*2), mean = mu, stddev = sigma),\n",
    "                           regularizer=regularizer);\n",
    "        conv2d_b = tf.Variable(tf.zeros(disparity_levels*2),name = 'onebyone'+str(id))\n",
    "        s   = tf.nn.conv2d(s, conv2d_W, strides=[1,1,1,1], padding='SAME') + conv2d_b\n",
    "        s = tf.nn.relu(s)\n",
    "    \n",
    "    #This is an FC layer implemented as 1x1 filter\n",
    "    conv2d_W = tf.get_variable(name = 'onebyone'+str(id),  regularizer=regularizer , initializer = tf.truncated_normal(shape=(1, 1, disparity_levels*2, disparity_levels), mean = mu, stddev = sigma));\n",
    "    conv2d_b = tf.Variable(tf.zeros(disparity_levels),name = 'onebyone'+str(id))\n",
    "    \n",
    "    s   = tf.nn.conv2d(s, conv2d_W, strides=[1,1, 1,1], padding='SAME') + conv2d_b \n",
    "    \n",
    "    #Soft Argmax -\n",
    "    neg_pred_d = -s;\n",
    "    sfmin = tf.nn.softmax(neg_pred_d,axis = 3)\n",
    "    sfshape = tf.shape(sfmin)\n",
    "    for i in range(disparity_levels):\n",
    "        sfmin1 = tf.concat([tf.scalar_mul(i,sfmin[:,:,:,i]) for i in range(disparity_levels)],axis=1)\n",
    "    sfmin_tem = tf.reshape(sfmin1,[sfshape[0],sfshape[3],sfshape[1],sfshape[2]])\n",
    "    sfmin2 = tf.reduce_sum(sfmin_tem, axis=1)\n",
    "    return (sfmin2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Estimate disparity and generate loss function\n",
    "disp_est = disparity_estimates_low(lx,ly)\n",
    "diff = tf.subtract( y, disp_est)\n",
    "L2 = tf.multiply(diff,diff)\n",
    "\n",
    "#compute regularization\n",
    "reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "reg_term = tf.contrib.layers.apply_regularization(regularizer, reg_variables)\n",
    "\n",
    "#net loss\n",
    "Loss = tf.reduce_mean(L2) + reg_term\n",
    "\n",
    "#optimizer function and learning rate\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
    "training_operation = optimizer.minimize(Loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "    header = file.readline().rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline())\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "    scale = float(file.readline().rstrip())\n",
    "    if scale < 0: # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>' # big-endian\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_values(limage, rimage, disparity):\n",
    "    limage = np.array(limage).astype(float)/255.0\n",
    "    rimage = np.array(rimage).astype(float)/255.0\n",
    "    d = np.array(disparity)\n",
    "    #print (\"disparity max\", np.amax(d))\n",
    "    #print(\"disparity shape\",d.shape)\n",
    "    disparity = np.array(d).astype(float);\n",
    "    return(limage,rimage,disparity)\n",
    "    \n",
    "import random\n",
    "max_disp = 200\n",
    "def get_image_disparity_for_index(filelist,indexandflip):\n",
    "    index = indexandflip/2\n",
    "    flipx = 0\n",
    "    flipy = (indexandflip&0x1) \n",
    "    index = reduced_indices[index]\n",
    "    limage = filelist[index].replace(\"disparity\",\"pngs\")[0:-5]+\".png\"\n",
    "    rimage = limage.replace(\"left\",\"right\")\n",
    "    limage_a = Image.open(limage)\n",
    "    limg = np.array(limage_a.crop((0,0,image_shape[1]*2,image_shape[0]*2)).resize((image_shape[1],image_shape[0])))\n",
    "    rimage_a = Image.open(rimage)\n",
    "    rimg = np.array(rimage_a.crop((0,0,image_shape[1]*2,image_shape[0]*2)).resize((image_shape[1],image_shape[0])))\n",
    "    pfmdata = readPFM(filelist[index][0:-1])\n",
    "    resizepfm = np.array(pfmdata[0])[0:image_shape[0]*2:2, 0:image_shape[1]*2:2]/4\n",
    "    \n",
    "    if (np.amax(resizepfm) < max_disparity/4):\n",
    "        limg = limage_a.crop((400,256,image_shape[1]+400,image_shape[0]+256))\n",
    "        rimg = rimage_a.crop((400,256,image_shape[1]+400,image_shape[0]+256))\n",
    "        resizepfm = np.array(pfmdata[0])[100:image_shape[0]+100, 200:image_shape[1]+200]\n",
    "    if (flipx == 1):\n",
    "        limg_temp = np.fliplr(limg)\n",
    "        rimg_temp = np.fliplr(rimg)\n",
    "        limg = rimg_temp\n",
    "        rimg = limg_temp\n",
    "        resizepfm = np.fliplr(resizepfm)\n",
    "    if (flipy == 1):\n",
    "        limg = np.flipud(limg)\n",
    "        rimg = np.flipud(rimg)\n",
    "        resizepfm = np.flipud(resizepfm)\n",
    "    return (limg,rimg,resizepfm)\n",
    "    \n",
    "def get_disparity_images(filelist,indices):\n",
    "    limages = []\n",
    "    rimages = []\n",
    "    disparities = []\n",
    "    for index in indices:\n",
    "        #print(filelist[index])\n",
    "        (limage,rimage, disparity) = get_image_disparity_for_index(filelist,index)\n",
    "        disparitynp = np.array(disparity).astype(float)\n",
    "        #print(\"disparity\", disparitynp.shape)\n",
    "        limage,rimage,disparity = normalize_values(np.array(limage)[0:image_shape[0],0:image_shape[1],0:3],\n",
    "                                                   np.array(rimage)[0:image_shape[0],0:image_shape[1],0:3], \n",
    "                                                   disparitynp[0:image_shape[0],0:image_shape[1]])\n",
    "        limages.append(limage)\n",
    "        rimages.append(rimage)\n",
    "        disparities.append(disparity)\n",
    "    return(limages,rimages,disparities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#file system related functions. Restrict calls to only the ones which matter\n",
    "\n",
    "import os\n",
    "import random\n",
    "max_disp_allowed = 16\n",
    "os.chdir(\"/home/ec2-user/project/data\")\n",
    "print(os.getcwd())\n",
    "file = open(\"filelist\",\"r\")\n",
    "filelist = file.readlines() \n",
    "all_indices = range(len(filelist))\n",
    "random.shuffle(all_indices)\n",
    "reduced_indices = []\n",
    "for index in range(len(filelist)):\n",
    "    pfmdata = readPFM(filelist[index][0:-1])\n",
    "    if (index % 100 == 0):\n",
    "        print(\"index \", index)\n",
    "    resizepfm = np.array(pfmdata[0])[0:image_shape[0]*2:2, 0:image_shape[1]*2:2]/4\n",
    "    \n",
    "    if (np.amax(resizepfm) < max_disparity/4):\n",
    "        resizepfm = np.array(pfmdata[0])[100:image_shape[0]+100, 200:image_shape[1]+200]\n",
    "    if np.amax(resizepfm) <= max_disp_allowed:\n",
    "        reduced_indices.append(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(valbatch_lx, valbatch_ly, valbatch_dis):\n",
    "    validation_accuracy = sess.run(Loss, feed_dict={lx: valbatch_lx, ly: valbatch_ly, y:valbatch_dis})\n",
    "    return validation_accuracy\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training routine for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_disp =0\n",
    "indices = range(len(reduced_indices)*2)\n",
    "random.shuffle(indices)\n",
    "training_indices = indices[-127:-1]\n",
    "indices = indices[0:-127]\n",
    "text_file = open(\"Output_disparity.txt\", \"w\")\n",
    "for i in range(EPOCHS):\n",
    "    print(\"EPOCH\", i)\n",
    "    random.shuffle(indices)\n",
    "    validation_indices = indices[-65:-1]\n",
    "    for batch_index in range(int(len(indices)/batch_size)-1):\n",
    "        (batch_lx, batch_ly, batch_dis) = get_disparity_images(filelist,indices[batch_index*batch_size:(batch_index+1)*batch_size])\n",
    "        batch_dis = np.array(batch_dis).astype(float)\n",
    "        print(\" disparity max\", np.amax(batch_dis))\n",
    "        _,loss = sess.run([training_operation,Loss], feed_dict={lx: batch_lx, ly: batch_ly, y:batch_dis})\n",
    "        random.shuffle(validation_indices)\n",
    "        (valbatch_lx, valbatch_ly, valbatch_dis) = get_disparity_images(filelist,validation_indices[0:batch_size])\n",
    "        validation_accuracy = evaluate(valbatch_lx, valbatch_ly, valbatch_dis)\n",
    "        print(\"Training Loss = {:.3f}\".format(loss))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        text_file.write(\"Training Loss = {:.3f}\".format(loss))\n",
    "        text_file.write(\"Validation Loss = {:.3f}\".format(validation_accuracy))\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './disparity_simple')\n",
    "print(\"Model saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility code for changing format\n",
    "os.chdir(\"/Users/bsubhash/Stanford_courses/Computer Vision/Project\")\n",
    "print(os.getcwd())\n",
    "file = open(\"./data/filelist\",\"r\")\n",
    "filelist = file.readlines() \n",
    "for index in range(len(filelist)):\n",
    "    #print(index)\n",
    "    limage_wp = filelist[index].replace(\"disparity\",\"frames_cleanpass_webp\")[0:-1]+\".webp\"\n",
    "    #print(limage_wp)\n",
    "    rimage_wp = limage_wp.replace(\"left\",\"right\")\n",
    "    #print(rimage_wp)\n",
    "    limage = (np.array(webp_read(\"./data/\" + limage_wp)))\n",
    "    rimage = (np.array(webp_read(\"./data/\" + rimage_wp)))\n",
    "    limage_png = \"./data/\" + limage_wp.replace(\".webp\",\".png\")\n",
    "    rimage_png = \"./data/\" + rimage_wp.replace(\".webp\",\".png\")\n",
    "    lim = Image.fromarray(limage[:,:,0:3])\n",
    "    rim = Image.fromarray(rimage[:,:,0:3])\n",
    "    lim.save(limage_png)\n",
    "    rim.save(rimage_png)\n",
    "    #plt.imshow(Image.open(rimage_png))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Routine\n",
    "new_saver = tf.train.import_meta_graph('disparity_simple' + '.meta', clear_devices=True)\n",
    "(limage,rimage, disparity) = get_disparity_images(filelist,training_indices[0:batch_size])\n",
    "new_saver.restore(sess, 'disparity_simple')\n",
    "dis_inf = sess.run(disp_est,feed_dict={lx:limage,ly:rimage})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some interesting Stats:\n",
    "error = np.abs(disparity-dis_inf)\n",
    "print(\"greater than 5% error\",100*np.sum(error>5).astype(int)/np.sum(error<15).astype(float))\n",
    "print(\"greater than 5% error\",100*np.sum(error>2).astype(int)/np.sum(error<15).astype(float))\n",
    "print(\"greater than 5% error\",100*np.sum(error>1).astype(int)/np.sum(error<15).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
